import openai
import os
import tiktoken
from dotenv import load_dotenv

load_dotenv()
api_key=os.getenv('openapi_key')
openai.api_key = api_key

def search_es(query):
    query={
        "size": 3,
        "query": {
            "bool": {
                "must": {
                    "multi_match": {
                        "query": query,
                        "fields": ["question^3", "text"],
                        "type": "best_fields"
                    }
                },
                "filter": {
                    "term": {
                        "course": "data-engineering-zoomcamp"
                    }
                }
            }
        }
    }
    response=ec.search(index=index_name, body=query)

    print(response)
    
    hits=response['hits']['hits']
    
    result_docs=[]

    for hit in hits:
        result_docs.append(hit['_source'])

    return result_docs

query="How do execute a command on a Kubernetes pod?"
search_es(query)

def build_prompt(query, search_results):
    
    prompt_template = """
    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.
    Use only the facts from the CONTEXT when answering the QUESTION.
    
    QUESTION: {question}
    
    CONTEXT:
    {context}
    """.strip()   

    context=""

    for doc in search_results:
        context= context+f"Q: {doc['question']}\nA: {doc['text']}\n\n"

    final_prompt=prompt_template.format(question=query, context=context).strip()

    return final_prompt

def call_llm(prompt):
    response = openai.chat.completions.create(
        model = 'gpt-4o',
        messages = [{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

def rag(adukko):
    question=adukko
    search_results=search_es(question)
    prompt=build_prompt(question, search_results)
    return call_llm(prompt)    


query = "How do execute a command on a Kubernetes pod?"
search_es(query)

query = "How do copy a file to a Docker container?"
sd = search_es(query)
bd = build_prompt(query,sd)
print(len(bd))

encoding = tiktoken.encoding_for_model("gpt-4o")
tokens = encoding.encode(bd)
print(len(tokens))
